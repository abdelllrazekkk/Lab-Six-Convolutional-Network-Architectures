{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d100f6",
   "metadata": {},
   "source": [
    "# Lab Assignment Six: Convolutional Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441cc890",
   "metadata": {},
   "source": [
    "In this lab, we will select a prediction task to perform on our dataset, evaluate a deep learning architecture and tune hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ab909",
   "metadata": {},
   "source": [
    "## Team Members:\n",
    "1) Mohammed Ahmed Abdelrazek Aboelela.\n",
    "\n",
    "2) Naim Barnett"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93defd6",
   "metadata": {},
   "source": [
    "## Dataset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eccb57c",
   "metadata": {},
   "source": [
    "Data Set : Intel Image Classification - https://www.kaggle.com/datasets/puneet6060/intel-image-classification?select=seg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38149cbf",
   "metadata": {},
   "source": [
    "### Overview and Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7868c",
   "metadata": {},
   "source": [
    "This dataset is imported from kaggle via this link (https://www.kaggle.com/datasets/puneet6060/intel-image-classification?select=seg_test). It is a very convenient dataset for our purposes as it contains around 25,000 images of size 150x150 distributed under 6 categories {'buildings' -> 0, 'forest' -> 1, 'glacier' -> 2, 'mountain' -> 3, 'sea' -> 4, 'street' -> 5 }, therefore it satisfies the requirements for this lab. It also has a well defined prediction task which is to classify the images into one of the 6 categories we defined. This is a set that is intended to be used in a Neural Network to do classification, but it's found to be really relvant to our purposes here so we use it. Third parties (like image search engines) would be really interested in such algorithms to be able to initially have a classifier that tells them whether a provided image falls under one of the 6 categories. The number of categories can also be expanded by including images from other classes and make the prediction task more and more inclusive of more relevant third parties. This data is really important because it is through which the machine can learn the different ways the image of a certain category can exist, the number of ways the pictures are taken, the different types of (buildings, forests, ...etc!) included can be very helpful in having a very powerful algorithm that can capture even the most unclear building/forests/..etc! image. Therefore, the sole judge of the efficiency of our algorithm is whether it well be able to predict data's classes with hidden labels correctly or not, and to which extent, of course, having the maximum efficiency in this regard is what only can be considered as a useful algorithm for third parties. Thus, an algorithm that predicts the correct label 80% of the time is always better than one that does it 60% of the time, and so on.\n",
    "\n",
    "For a more detailed description of the dataset, The 25,000 is distributed among three different folders, (train, test, and prediction). For our purposes, we will mainly focus on the images in the (train) folder, their number is 14034 images. In the (train) folder, we have six folders, a folder for each category of our six categories and each one of these folders has many images of the respective category with different orientations and shapes. Moreover, the each of the images is of the (RGB) type, thus having 3 channels per pixel, and we have 150 x 150 = 22500 pixels.\n",
    "\n",
    "Before we start, it is worth mentioning that the computational limitations for my machine didn't allow me to fully explore the gabor kernel process, but it is included if you wanna run it on your machine!\n",
    "\n",
    "It is worth noting that I relied heavily on the professor's notebook, so everything I took from there will be cited with \"(Inspired by the professor's notebook)\" beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ed7ae",
   "metadata": {},
   "source": [
    "# Preparation (3 points total)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca169c4",
   "metadata": {},
   "source": [
    "## [1.5 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5e553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e86053c",
   "metadata": {},
   "source": [
    "## [1.5 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb5a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de2f6796",
   "metadata": {},
   "source": [
    "# Modeling (6 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff83aae",
   "metadata": {},
   "source": [
    "## [1.5 points]  Setup the training to use data expansion in Keras. Explain why the chosen data expansion techniques are appropriate for your dataset. You can use the keras fit generator as a pre-processing step OR in the optimization loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff3f731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "792e27aa",
   "metadata": {},
   "source": [
    "## [2 points] Create a convolutional neural network to use on your data using Keras. Investigate at least two different convolutional network architectures (and investigate changing some parameters of each architecture--at minimum have two variations of each network for a total of four models trained). Use the method of train/test splitting and evaluation metric that you argued for at the beginning of the lab. Visualize the performance of the training and validation sets per iteration (use the \"history\" parameter of Keras). Be sure that models converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9bd468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0ab4657",
   "metadata": {},
   "source": [
    "## [1.5 points] Visualize the final results of the CNNs and interpret/compare the performances. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c415b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acd344d4",
   "metadata": {},
   "source": [
    "## [1 points] Compare the performance of your convolutional network to a standard multi-layer perceptron (MLP)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab28b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1af3a2d0",
   "metadata": {},
   "source": [
    "# Exceptional Work (1 points total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af453fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1712fa14",
   "metadata": {},
   "source": [
    "## You have free reign to provide additional analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1871a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "502d996b",
   "metadata": {},
   "source": [
    "## One idea (required for 7000 level students): Use transfer learning to pre-train the weights of your initial layers of your CNN. Compare the performance when using transfer learning to training without transfer learning (i.e., compare to your best model from above) in terms of classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea26f3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
